# API Documentation - AIDefCom AI Service

**Base URL:** `https://<your-app>.azurewebsites.net`  
**Version:** 2.3.3  
**Swagger UI:** `https://<your-app>.azurewebsites.net/docs`

---

## üìã Table of Contents
1. [Voice Authentication APIs](#voice-authentication-apis)
2. [Speech-to-Text WebSocket](#speech-to-text-websocket)
3. [Question Management APIs](#question-management-apis)
4. [Health Check](#health-check)
5. [Response Format Standards](#response-format-standards)
6. [Error Codes](#error-codes)

---

## üé§ Voice Authentication APIs

### 1. Enroll Voice Sample
**Endpoint:** `POST /voice/users/{user_id}/enroll`

ƒêƒÉng k√Ω m·∫´u gi·ªçng n√≥i cho m·ªôt user. C·∫ßn t·ªëi thi·ªÉu **3 m·∫´u** ƒë·ªÉ ho√†n t·∫•t enrollment.

#### Request
```http
POST /voice/users/{user_id}/enroll
Content-Type: multipart/form-data

audio_file: <binary audio file>
```

**Parameters:**
- `user_id` (path, required): User ID c·∫ßn enroll
- `audio_file` (form-data, required): File audio (WAV/MP3/FLAC, max 10MB, khuy·∫øn ngh·ªã 3-5 gi√¢y)

#### Response
```json
{
  "type": "enrollment",
  "success": true,
  "user_id": "USR001",
  "enrollment_count": 2,
  "min_required": 3,
  "is_complete": false,
  "message": "Enrollment sample 2/3 saved successfully"
}
```

**Response Fields:**
- `success` (boolean): Th√†nh c√¥ng hay kh√¥ng
- `user_id` (string): User ID ƒë√£ enroll
- `enrollment_count` (int): S·ªë m·∫´u ƒë√£ c√≥
- `min_required` (int): S·ªë m·∫´u t·ªëi thi·ªÉu c·∫ßn (3)
- `is_complete` (boolean): ƒê√£ ƒë·ªß 3 m·∫´u ch∆∞a
- `message` (string): Th√¥ng b√°o chi ti·∫øt

#### Status Codes
- `200`: Enrollment th√†nh c√¥ng
- `400`: Audio kh√¥ng h·ª£p l·ªá ho·∫∑c ch·∫•t l∆∞·ª£ng k√©m
- `500`: L·ªói server

---

### 2. Identify Speaker
**Endpoint:** `POST /voice/identify`

Nh·∫≠n di·ªán ng∆∞·ªùi n√≥i t·ª´ m·∫´u gi·ªçng n√≥i (so s√°nh v·ªõi t·∫•t c·∫£ users ƒë√£ enroll).

#### Request
```http
POST /voice/identify
Content-Type: multipart/form-data

audio_file: <binary audio file>
```

**Parameters:**
- `audio_file` (form-data, required): File audio c·∫ßn nh·∫≠n di·ªán (WAV/MP3/FLAC, max 10MB)

#### Response (Success - Identified)
```json
{
  "type": "identification",
  "success": true,
  "identified": true,
  "speaker_id": "USR001",
  "speaker_name": "Nguyen Van A",
  "confidence": 0.92,
  "score": 0.92,
  "message": "Speaker identified successfully"
}
```

#### Response (No Match)
```json
{
  "type": "identification",
  "success": true,
  "identified": false,
  "speaker_id": null,
  "speaker_name": null,
  "confidence": 0.0,
  "score": 0.58,
  "message": "No matching speaker found"
}
```

**Response Fields:**
- `identified` (boolean): C√≥ nh·∫≠n di·ªán ƒë∆∞·ª£c hay kh√¥ng
- `speaker_id` (string|null): User ID c·ªßa ng∆∞·ªùi ƒë∆∞·ª£c nh·∫≠n di·ªán
- `speaker_name` (string|null): T√™n hi·ªÉn th·ªã
- `confidence` (float): ƒê·ªô tin c·∫≠y (0-1)
- `score` (float): ƒêi·ªÉm t∆∞∆°ng ƒë·ªìng th·ª±c t·∫ø (0-1)
- `message` (string): Th√¥ng b√°o

**Threshold:** Score >= 0.7 m·ªõi ƒë∆∞·ª£c coi l√† match

#### Status Codes
- `200`: Process th√†nh c√¥ng (check `identified` field)
- `400`: Audio kh√¥ng h·ª£p l·ªá ho·∫∑c kh√¥ng c√≥ users n√†o ƒë√£ enroll
- `500`: L·ªói server

---

### 3. Verify Voice
**Endpoint:** `POST /voice/users/{user_id}/verify`

X√°c th·ª±c xem m·∫´u gi·ªçng c√≥ kh·ªõp v·ªõi user ID ƒë√£ claim hay kh√¥ng (1:1 verification).

#### Request
```http
POST /voice/users/{user_id}/verify
Content-Type: multipart/form-data

audio_file: <binary audio file>
```

**Parameters:**
- `user_id` (path, required): User ID c·∫ßn verify
- `audio_file` (form-data, required): File audio ƒë·ªÉ verify (WAV/MP3/FLAC, max 10MB)

#### Response (Verified - Match)
```json
{
  "type": "verification",
  "success": true,
  "verified": true,
  "claimed_id": "USR001",
  "speaker_id": "USR001",
  "match": true,
  "confidence": 0.89,
  "score": 0.89,
  "message": "Voice verified successfully"
}
```

#### Response (Not Verified - No Match)
```json
{
  "type": "verification",
  "success": false,
  "verified": false,
  "claimed_id": "USR001",
  "speaker_id": "USR002",
  "match": false,
  "confidence": 0.65,
  "score": 0.65,
  "message": "Voice verification failed - speaker mismatch"
}
```

#### Response (User Not Enrolled)
```json
{
  "type": "verification",
  "success": false,
  "verified": false,
  "claimed_id": "USR999",
  "speaker_id": null,
  "match": false,
  "confidence": 0.0,
  "score": 0.0,
  "message": "User not enrolled or insufficient samples"
}
```

**Response Fields:**
- `verified` (boolean): C√≥ verify th√†nh c√¥ng kh√¥ng
- `claimed_id` (string): User ID ƒë∆∞·ª£c claim
- `speaker_id` (string|null): User ID th·ª±c s·ª± nh·∫≠n di·ªán ƒë∆∞·ª£c
- `match` (boolean): `claimed_id == speaker_id`
- `confidence` (float): ƒê·ªô tin c·∫≠y (0-1)
- `score` (float): ƒêi·ªÉm t∆∞∆°ng ƒë·ªìng (0-1)
- `message` (string): Th√¥ng b√°o

**Use Cases:**
- Authentication: X√°c th·ª±c user qua gi·ªçng n√≥i
- Access Control: C·∫•p quy·ªÅn truy c·∫≠p n·∫øu voice kh·ªõp
- Security: Ph√°t hi·ªán gi·∫£ m·∫°o gi·ªçng n√≥i

#### Status Codes
- `200`: Process th√†nh c√¥ng (check `verified` field)
- `400`: Audio kh√¥ng h·ª£p l·ªá ho·∫∑c user ch∆∞a enroll ƒë·ªß
- `500`: L·ªói server

---

## üéôÔ∏è Speech-to-Text WebSocket

### WebSocket Endpoint
**Endpoint:** `ws://<host>/ws/stt` (ho·∫∑c `wss://` cho HTTPS)

Real-time speech-to-text streaming v·ªõi Azure Cognitive Services.

#### Connection
```javascript
const ws = new WebSocket('wss://<your-app>.azurewebsites.net/ws/stt');

ws.onopen = () => {
  console.log('Connected to STT WebSocket');
  
  // Send initialization (optional)
  ws.send(JSON.stringify({
    session_id: "session_123",
    lang: "vi-VN"
  }));
  
  // Backend s·∫Ω T·ª∞ ƒê·ªòNG nh·∫≠n di·ªán ng∆∞·ªùi n√≥i t·ª´ audio
  // Kh√¥ng c·∫ßn g·ª≠i user_id hay speaker name
};
```

#### Initialization Message (Optional)
Sau khi connect, FE c√≥ th·ªÉ g·ª≠i JSON message ƒë·ªÉ config:

```json
{
  "session_id": "session_123",
  "lang": "vi-VN",
  "phrases": "AI,Machine Learning,Deep Learning"
}
```

**Fields:**
- `session_id` (string, optional): Session ID ƒë·ªÉ group transcripts
- `lang` (string, optional): Language code (default: "vi-VN")
- `phrases` (string, optional): Phrase hints ph√¢n c√°ch b·∫±ng d·∫•u ph·∫©y

**‚ö†Ô∏è L∆∞u √Ω quan tr·ªçng:**
- **KH√îNG c·∫ßn g·ª≠i `user_id` hay `speaker`** - Backend s·∫Ω t·ª± ƒë·ªông nh·∫≠n di·ªán ng∆∞·ªùi n√≥i t·ª´ audio b·∫±ng voice identification
- Speaker name v√† user_id s·∫Ω ƒë∆∞·ª£c tr·∫£ v·ªÅ trong events `recognized`

#### Sending Audio
```javascript
// Send audio chunks as binary data
const audioBlob = new Blob([audioData], { type: 'audio/wav' });
ws.send(audioBlob);

// Or send raw audio buffer
ws.send(audioBuffer);
```

#### Automatic Speaker Identification
**Backend t·ª± ƒë·ªông nh·∫≠n di·ªán ng∆∞·ªùi n√≥i:**

1. **Trong qu√° tr√¨nh stream**, backend s·∫Ω:
   - Thu th·∫≠p audio chunks t·ª´ FE
   - ƒê·ªãnh k·ª≥ (m·ªói 0.6s) ch·∫°y voice identification
   - So s√°nh v·ªõi database users ƒë√£ enroll (‚â•3 samples)
   - T·ª± ƒë·ªông g√°n `speaker` v√† `user_id` v√†o events

2. **FE nh·∫≠n k·∫øt qu·∫£ qua events:**
   ```json
   {
     "event": "recognized",
     "text": "Xin ch√†o c√°c b·∫°n",
     "speaker": "Nguyen Van A",
     "user_id": "USR001",
     "timestamp": "2025-11-16T10:30:05Z"
   }
   ```

3. **N·∫øu kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c:**
   ```json
   {
     "event": "recognized",
     "text": "Xin ch√†o c√°c b·∫°n",
     "speaker": "Kh√°ch",
     "timestamp": "2025-11-16T10:30:05Z"
   }
   ```

**∆Øu ƒëi·ªÉm:**
- FE kh√¥ng c·∫ßn bi·∫øt tr∆∞·ªõc user_id
- T·ª± ƒë·ªông ph√°t hi·ªán khi ng∆∞·ªùi n√≥i thay ƒë·ªïi
- Support multi-speaker trong c√πng session

#### Receiving Events
```javascript
ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  
  switch(data.event) {
    case 'recognizing':
      // Interim result (real-time)
      console.log('Recognizing:', data.text);
      break;
      
    case 'recognized':
      // Final result for segment
      console.log('Recognized:', data.text);
      console.log('Speaker:', data.speaker);
      break;
      
    case 'session_started':
      console.log('Session ID:', data.session_id);
      break;
      
    case 'session_stopped':
      console.log('Total lines:', data.total_lines);
      break;
      
    case 'error':
      console.error('Error:', data.message);
      break;
  }
};
```

#### Event Types

**1. session_started**
```json
{
  "event": "session_started",
  "session_id": "abc123",
  "timestamp": "2025-11-16T10:30:00Z"
}
```

**2. recognizing** (real-time interim results)
```json
{
  "event": "recognizing",
  "text": "Xin ch√†o c√°c b·∫°n",
  "speaker": "Nguyen Van A",
  "timestamp": "2025-11-16T10:30:05Z"
}
```

**3. recognized** (final segment result)
```json
{
  "event": "recognized",
  "text": "Xin ch√†o c√°c b·∫°n, h√¥m nay ch√∫ng ta s·∫Ω h·ªçc v·ªÅ AI.",
  "speaker": "Nguyen Van A",
  "user_id": "USR001",
  "timestamp": "2025-11-16T10:30:08Z"
}
```

**Fields:**
- `speaker` (string): T√™n ng∆∞·ªùi n√≥i (t·ª± ƒë·ªông identify)
- `user_id` (string, optional): User ID n·∫øu nh·∫≠n di·ªán ƒë∆∞·ª£c
- N·∫øu kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c: `speaker="Kh√°ch"`, kh√¥ng c√≥ `user_id`

**4. session_stopped**
```json
{
  "event": "session_stopped",
  "session_id": "abc123",
  "total_lines": 15,
  "message": "Session ended and transcript saved"
}
```

**5. error**
```json
{
  "event": "error",
  "message": "Audio stream interrupted",
  "code": "AUDIO_ERROR"
}
```

#### Ending Session
```javascript
// Send "stop" command
ws.send("stop");

// Or close connection
ws.close();
```

**Note:** Khi k·∫øt th√∫c session, transcript s·∫Ω t·ª± ƒë·ªông ƒë∆∞·ª£c l∆∞u v√†o external API `/api/transcripts`.

#### Audio Requirements
- **Format:** PCM 16-bit, mono
- **Sample Rate:** 16000 Hz
- **Chunk Size:** 3200-6400 bytes (0.1-0.2s)
- **Max Total Size:** No limit (streaming)

---

## ‚ùì Question Management APIs

### 1. Check Duplicate Question
**Endpoint:** `POST /questions/check-duplicate`

Ki·ªÉm tra xem c√¢u h·ªèi c√≥ b·ªã tr√πng l·∫∑p trong session hay kh√¥ng.

#### Request
```json
{
  "session_id": "session_123",
  "question_text": "AI l√† g√¨?",
  "threshold": 0.85
}
```

**Fields:**
- `session_id` (string, required): Session ID
- `question_text` (string, required): N·ªôi dung c√¢u h·ªèi
- `threshold` (float, optional): Ng∆∞·ª°ng t∆∞∆°ng ƒë·ªìng (default: 0.85)

#### Response (Not Duplicate)
```json
{
  "is_duplicate": false,
  "question_text": "AI l√† g√¨?",
  "similar_questions": [],
  "message": "‚úÖ C√¢u h·ªèi h·ª£p l·ªá, ch∆∞a b·ªã tr√πng."
}
```

#### Response (Duplicate Found)
```json
{
  "is_duplicate": true,
  "question_text": "AI l√† g√¨?",
  "similar_questions": [
    {
      "text": "Tr√≠ tu·ªá nh√¢n t·∫°o l√† g√¨?",
      "score": 0.92,
      "fuzzy_score": 0.85,
      "semantic_score": 0.92
    }
  ],
  "message": "‚ö†Ô∏è C√¢u h·ªèi tr√πng l·∫∑p! T√¨m th·∫•y 1 c√¢u t∆∞∆°ng t·ª±."
}
```

---

### 2. Register Question
**Endpoint:** `POST /questions/register`

ƒêƒÉng k√Ω c√¢u h·ªèi m·ªõi v√†o session (kh√¥ng check duplicate).

#### Request
```json
{
  "session_id": "session_123",
  "question_text": "Machine Learning ho·∫°t ƒë·ªông th·∫ø n√†o?",
  "speaker": "Nguyen Van A",
  "timestamp": "2025-11-16T10:30:00Z"
}
```

**Fields:**
- `session_id` (string, required): Session ID
- `question_text` (string, required): N·ªôi dung c√¢u h·ªèi
- `speaker` (string, optional): Ng∆∞·ªùi h·ªèi
- `timestamp` (string, optional): Th·ªùi gian h·ªèi (ISO format)

#### Response
```json
{
  "success": true,
  "question_id": "q_abc123",
  "total_questions": 5,
  "message": "‚úÖ C√¢u h·ªèi ƒë√£ ƒë∆∞·ª£c l∆∞u. T·ªïng: 5"
}
```

---

### 3. Check and Register (Combo)
**Endpoint:** `POST /questions/check-and-register`

Check duplicate + register n·∫øu kh√¥ng tr√πng (m·ªôt b∆∞·ªõc).

#### Request
```json
{
  "session_id": "session_123",
  "question_text": "Deep Learning kh√°c g√¨ Machine Learning?",
  "speaker": "Tran Thi B",
  "timestamp": "2025-11-16T10:35:00Z"
}
```

#### Response (Registered)
```json
{
  "is_duplicate": false,
  "question_text": "Deep Learning kh√°c g√¨ Machine Learning?",
  "similar_questions": [],
  "message": "‚úÖ C√¢u h·ªèi ƒë√£ ƒë∆∞·ª£c l∆∞u. T·ªïng: 6"
}
```

#### Response (Duplicate - Not Registered)
```json
{
  "is_duplicate": true,
  "question_text": "Deep Learning kh√°c g√¨ Machine Learning?",
  "similar_questions": [
    {
      "text": "S·ª± kh√°c bi·ªát gi·ªØa Deep Learning v√† ML?",
      "score": 0.89,
      "fuzzy_score": 0.82,
      "semantic_score": 0.89
    }
  ],
  "message": "‚ö†Ô∏è C√¢u h·ªèi tr√πng l·∫∑p! Kh√¥ng th·ªÉ ƒëƒÉng k√Ω."
}
```

---

### 4. Get Session Questions
**Endpoint:** `GET /questions/session/{session_id}`

L·∫•y t·∫•t c·∫£ c√¢u h·ªèi trong m·ªôt session.

#### Request
```http
GET /questions/session/session_123
```

#### Response
```json
{
  "session_id": "session_123",
  "questions": [
    {
      "id": "q_001",
      "text": "AI l√† g√¨?",
      "speaker": "Nguyen Van A",
      "timestamp": "2025-11-16T10:30:00Z"
    },
    {
      "id": "q_002",
      "text": "Machine Learning ho·∫°t ƒë·ªông th·∫ø n√†o?",
      "speaker": "Nguyen Van A",
      "timestamp": "2025-11-16T10:32:00Z"
    }
  ],
  "total": 2
}
```

---

### 5. Clear Session Questions
**Endpoint:** `DELETE /questions/session/{session_id}`

X√≥a t·∫•t c·∫£ c√¢u h·ªèi trong session.

#### Request
```http
DELETE /questions/session/session_123
```

#### Response
```json
{
  "success": true,
  "session_id": "session_123",
  "deleted": 5,
  "message": "‚úÖ ƒê√£ x√≥a 5 c√¢u h·ªèi."
}
```

---

## ‚ù§Ô∏è Health Check

### Health Endpoint
**Endpoint:** `GET /health`

Ki·ªÉm tra tr·∫°ng th√°i server.

#### Request
```http
GET /health
```

#### Response
```json
{
  "status": "ok"
}
```

**Legacy Endpoint:** `GET /healthz` (gi·ªØ ƒë·ªÉ t∆∞∆°ng th√≠ch)

---

## üì¶ Response Format Standards

### Success Response (Voice Auth)
```json
{
  "type": "enrollment|identification|verification",
  "success": true,
  "user_id": "USR001",
  "speaker_id": "USR001",
  "confidence": 0.92,
  "score": 0.92,
  "message": "Success message"
}
```

### Error Response
```json
{
  "error": "Error message description",
  "detail": "Technical detail (optional)"
}
```

### Question Response
```json
{
  "is_duplicate": false,
  "question_text": "Question content",
  "similar_questions": [],
  "message": "Status message"
}
```

---

## ‚ö†Ô∏è Error Codes

| Status Code | Description | Common Causes |
|-------------|-------------|---------------|
| 200 | Success | Request processed successfully |
| 400 | Bad Request | Invalid audio, missing parameters, validation failed |
| 404 | Not Found | Endpoint kh√¥ng t·ªìn t·∫°i |
| 500 | Internal Server Error | Server error, service unavailable |

### Common Error Messages

#### Voice Authentication
- `"Empty audio data"` - File audio r·ªóng
- `"Audio too large (>10MB)"` - File qu√° l·ªõn
- `"User not enrolled or insufficient samples"` - User ch∆∞a enroll ƒë·ªß 3 m·∫´u
- `"No enrolled users found"` - Kh√¥ng c√≥ user n√†o ƒë√£ enroll (identify)
- `"Audio quality too low"` - Ch·∫•t l∆∞·ª£ng audio kh√¥ng ƒë·ªß (qu√° nh·ªè, nhi·ªÖu, v.v.)

#### WebSocket
- `"Audio stream interrupted"` - K·∫øt n·ªëi audio b·ªã gi√°n ƒëo·∫°n
- `"Session initialization failed"` - Kh√¥ng th·ªÉ kh·ªüi t·∫°o session
- `"Recognition error"` - L·ªói nh·∫≠n d·∫°ng gi·ªçng n√≥i

#### Questions
- `"Invalid session_id"` - Session ID kh√¥ng h·ª£p l·ªá
- `"Question text is required"` - Thi·∫øu n·ªôi dung c√¢u h·ªèi
- `"Service unavailable"` - Redis ho·∫∑c semantic service kh√¥ng kh·∫£ d·ª•ng

---

## üîê Authentication & Security

**Current Status:** No authentication required (internal/trusted network)

**Production Recommendations:**
1. Add API Key authentication
2. Implement rate limiting
3. Enable CORS restrictions (currently `*`)
4. Use HTTPS only
5. Add request signing for voice samples

---

## üåê Environment Variables (FE c·∫ßn bi·∫øt)

Frontend n√™n config c√°c URL sau:

```javascript
// Production
const API_BASE_URL = 'https://<your-app>.azurewebsites.net';
const WS_BASE_URL = 'wss://<your-app>.azurewebsites.net';

// Development (local)
const API_BASE_URL = 'http://localhost:8000';
const WS_BASE_URL = 'ws://localhost:8000';
```

---

## üìù Integration Examples

### Voice Authentication Flow

```javascript
// 1. Enroll user (3 samples)
for (let i = 0; i < 3; i++) {
  const formData = new FormData();
  formData.append('audio_file', audioBlob);
  
  const response = await fetch(`${API_BASE_URL}/voice/users/USR001/enroll`, {
    method: 'POST',
    body: formData
  });
  
  const result = await response.json();
  console.log(`Sample ${i+1}/3:`, result.message);
}

// 2. Verify user
const formData = new FormData();
formData.append('audio_file', audioBlob);

const verifyResponse = await fetch(`${API_BASE_URL}/voice/users/USR001/verify`, {
  method: 'POST',
  body: formData
});

const verifyResult = await verifyResponse.json();
if (verifyResult.verified) {
  console.log('Authentication successful!');
} else {
  console.log('Authentication failed:', verifyResult.message);
}
```

### Question Management Flow

```javascript
// Check and register question
const checkResponse = await fetch(`${API_BASE_URL}/questions/check-and-register`, {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    session_id: 'session_123',
    question_text: 'AI l√† g√¨?',
    speaker: 'Nguyen Van A',
    timestamp: new Date().toISOString()
  })
});

const result = await checkResponse.json();
if (result.is_duplicate) {
  alert('C√¢u h·ªèi b·ªã tr√πng!');
  console.log('Similar:', result.similar_questions);
} else {
  alert('C√¢u h·ªèi ƒë√£ ƒë∆∞·ª£c l∆∞u!');
}
```

---

## üöÄ Quick Start Guide

### Step 1: Health Check
```bash
curl https://<your-app>.azurewebsites.net/health
```

### Step 2: View API Docs
Open browser: `https://<your-app>.azurewebsites.net/docs`

### Step 3: Test Voice Enroll
```bash
curl -X POST "https://<your-app>.azurewebsites.net/voice/users/USR001/enroll" \
  -F "audio_file=@sample.wav"
```

### Step 4: Test Question Check
```bash
curl -X POST "https://<your-app>.azurewebsites.net/questions/check-duplicate" \
  -H "Content-Type: application/json" \
  -d '{"session_id":"test","question_text":"AI l√† g√¨?"}'
```

---

## üìû Support

- **Swagger UI:** `/docs`
- **Health Check:** `/health`
- **Base Info:** `GET /` (root endpoint)

**Note:** T·∫•t c·∫£ endpoints ƒë·ªÅu support CORS `*` (hi·ªán t·∫°i). Production n√™n restrict l·∫°i.
